{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a588ebdca46a434aaae91c40637ef540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd515aa54fa9406986e33befda6fe564",
              "IPY_MODEL_d2b1c565b9b147a9ad175ea26afa556e",
              "IPY_MODEL_617504ef856c495e9499d76c6e053dde"
            ],
            "layout": "IPY_MODEL_9eb1c54014124877ba398db43e202516"
          }
        },
        "bd515aa54fa9406986e33befda6fe564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f7d9eea7f044f81a542a89c087b6518",
            "placeholder": "​",
            "style": "IPY_MODEL_ca5c635e6dd549c8b3cde8dd97472148",
            "value": "config.json: 100%"
          }
        },
        "d2b1c565b9b147a9ad175ea26afa556e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc0b4e70547040b3a4689bebcf2f56d6",
            "max": 1585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_538eeb4f66524c1bbf70de73b8308597",
            "value": 1585
          }
        },
        "617504ef856c495e9499d76c6e053dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cce6bdb51c5c4d6cb56df3d4602639f8",
            "placeholder": "​",
            "style": "IPY_MODEL_df0f08b504cd4487b7fc768878ac0c4d",
            "value": " 1.58k/1.58k [00:00&lt;00:00, 182kB/s]"
          }
        },
        "9eb1c54014124877ba398db43e202516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f7d9eea7f044f81a542a89c087b6518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca5c635e6dd549c8b3cde8dd97472148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc0b4e70547040b3a4689bebcf2f56d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "538eeb4f66524c1bbf70de73b8308597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cce6bdb51c5c4d6cb56df3d4602639f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df0f08b504cd4487b7fc768878ac0c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb4e98d8609941c48cb9aefd11233f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df148068c59e4551a7d39b4fb3e2538a",
              "IPY_MODEL_49332686f85b4e6aa0e10aaed6a85989",
              "IPY_MODEL_e052adf591d14ba5ab5298eeb5b01339"
            ],
            "layout": "IPY_MODEL_913e0c7cf9fb4741baa594d83fadd6d8"
          }
        },
        "df148068c59e4551a7d39b4fb3e2538a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e3e95a94d5e46dd934dd46c1d3e5efd",
            "placeholder": "​",
            "style": "IPY_MODEL_7304e9bda7584e3c9127251e6cb9ac9b",
            "value": "model.safetensors: 100%"
          }
        },
        "49332686f85b4e6aa0e10aaed6a85989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93fdde6d32b24402bee1978b7e44f62c",
            "max": 1625222120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a412f158bafc4d08899a097d10351f2c",
            "value": 1625222120
          }
        },
        "e052adf591d14ba5ab5298eeb5b01339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4ed72e9d5754cc6984717b2b3b8aeba",
            "placeholder": "​",
            "style": "IPY_MODEL_7426c5ba983b4354b4f2f748827243ce",
            "value": " 1.63G/1.63G [00:10&lt;00:00, 146MB/s]"
          }
        },
        "913e0c7cf9fb4741baa594d83fadd6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e3e95a94d5e46dd934dd46c1d3e5efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7304e9bda7584e3c9127251e6cb9ac9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93fdde6d32b24402bee1978b7e44f62c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a412f158bafc4d08899a097d10351f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4ed72e9d5754cc6984717b2b3b8aeba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7426c5ba983b4354b4f2f748827243ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e63d3fb24a641bea6dde2de0c203a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab3bac98397640d19cf50e1d6911976a",
              "IPY_MODEL_9a14358b6f0041bda7f5e8e5a568317d",
              "IPY_MODEL_6e290ec4e6244c699b60e5c799c4af64"
            ],
            "layout": "IPY_MODEL_22a1e600820e4bcbb86fa697c398bb27"
          }
        },
        "ab3bac98397640d19cf50e1d6911976a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2553e9c03fa84ecd8e5dff5fa76e9d7a",
            "placeholder": "​",
            "style": "IPY_MODEL_7984576269214f7d95c5fe2534f2bde9",
            "value": "generation_config.json: 100%"
          }
        },
        "9a14358b6f0041bda7f5e8e5a568317d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5cf9f548dcb41e7a307bf52e84d33b8",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c351fde66fd4f769a82817c2a759067",
            "value": 363
          }
        },
        "6e290ec4e6244c699b60e5c799c4af64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_600f553b686d45ff9835208ee90fa130",
            "placeholder": "​",
            "style": "IPY_MODEL_9e6b2e639efb4f578ccfd8cd8d396be7",
            "value": " 363/363 [00:00&lt;00:00, 44.4kB/s]"
          }
        },
        "22a1e600820e4bcbb86fa697c398bb27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2553e9c03fa84ecd8e5dff5fa76e9d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7984576269214f7d95c5fe2534f2bde9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5cf9f548dcb41e7a307bf52e84d33b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c351fde66fd4f769a82817c2a759067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "600f553b686d45ff9835208ee90fa130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e6b2e639efb4f578ccfd8cd8d396be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d682ecf8ca7491d9b5a1fdad6dfc0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be7a9b82a8c04b1f9052db947f16fbb9",
              "IPY_MODEL_03e98aa3612a442f8aacb93455e3d76c",
              "IPY_MODEL_69e68593d12e4af484fde0a3bc2c55b7"
            ],
            "layout": "IPY_MODEL_6c797f3c633a4c669dfa85e6522525b2"
          }
        },
        "be7a9b82a8c04b1f9052db947f16fbb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_474f0c8236d949d693cbe924817f32af",
            "placeholder": "​",
            "style": "IPY_MODEL_f9044a6cd43249369871b731cf8c3660",
            "value": "vocab.json: 100%"
          }
        },
        "03e98aa3612a442f8aacb93455e3d76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd250f3646b74cd8876dfff55762f8a7",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1b1449ed86c490e8b6836c784223107",
            "value": 898823
          }
        },
        "69e68593d12e4af484fde0a3bc2c55b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_949e2cdadd93465bba89699c5d3c91b8",
            "placeholder": "​",
            "style": "IPY_MODEL_4c439f422e6c4ac2bff16890623714d7",
            "value": " 899k/899k [00:00&lt;00:00, 6.90MB/s]"
          }
        },
        "6c797f3c633a4c669dfa85e6522525b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474f0c8236d949d693cbe924817f32af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9044a6cd43249369871b731cf8c3660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd250f3646b74cd8876dfff55762f8a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b1449ed86c490e8b6836c784223107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "949e2cdadd93465bba89699c5d3c91b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c439f422e6c4ac2bff16890623714d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4eecfb355b14983add3dfbee95f8e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8ad12c2f5b24e03888f5db967b28801",
              "IPY_MODEL_f4d78394b40145239236189376c5a2bb",
              "IPY_MODEL_b5ccbb0f4e3f4115a8f56b003d054eae"
            ],
            "layout": "IPY_MODEL_816b400dd98044db95d8989ededd3f0f"
          }
        },
        "b8ad12c2f5b24e03888f5db967b28801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bef8ce29a3c946d2b142d7cfed24e35c",
            "placeholder": "​",
            "style": "IPY_MODEL_4a63f80b046a461aa3f3de1b73ee34a2",
            "value": "merges.txt: 100%"
          }
        },
        "f4d78394b40145239236189376c5a2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f80c07e487d4efba62a8370124265f6",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3208064469ce4a6fa9eaaf17a5273957",
            "value": 456318
          }
        },
        "b5ccbb0f4e3f4115a8f56b003d054eae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_491c5291c7504e7792e1c59fe58e7761",
            "placeholder": "​",
            "style": "IPY_MODEL_5265b47645264b10ad45093234ed93bc",
            "value": " 456k/456k [00:00&lt;00:00, 3.45MB/s]"
          }
        },
        "816b400dd98044db95d8989ededd3f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef8ce29a3c946d2b142d7cfed24e35c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a63f80b046a461aa3f3de1b73ee34a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f80c07e487d4efba62a8370124265f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3208064469ce4a6fa9eaaf17a5273957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "491c5291c7504e7792e1c59fe58e7761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5265b47645264b10ad45093234ed93bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2eee307c539461ab77b583666438b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0c4c147e6d0472084799a5358313cea",
              "IPY_MODEL_3c7223b39d874c9cb7b0589f40ef317a",
              "IPY_MODEL_faf2bb23de324a1593a19c792e7ac2a7"
            ],
            "layout": "IPY_MODEL_95f126f0ba16470fa61ab14ffd03eccf"
          }
        },
        "c0c4c147e6d0472084799a5358313cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09ca7b0564474f24ab6f790098d60630",
            "placeholder": "​",
            "style": "IPY_MODEL_a55533a6276d4a0eb429463ab48fdabd",
            "value": "tokenizer.json: 100%"
          }
        },
        "3c7223b39d874c9cb7b0589f40ef317a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_701b443a92db427db9e7b076de57d60b",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c20f7cd5d8cc496bb127770886a784c4",
            "value": 1355863
          }
        },
        "faf2bb23de324a1593a19c792e7ac2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6255087c93b4d0fa2fbbca815c651d6",
            "placeholder": "​",
            "style": "IPY_MODEL_371c7f1e1e214a6b936ea792c529498e",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 6.81MB/s]"
          }
        },
        "95f126f0ba16470fa61ab14ffd03eccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09ca7b0564474f24ab6f790098d60630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55533a6276d4a0eb429463ab48fdabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "701b443a92db427db9e7b076de57d60b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c20f7cd5d8cc496bb127770886a784c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6255087c93b4d0fa2fbbca815c651d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "371c7f1e1e214a6b936ea792c529498e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "VslbhILl02mW",
        "outputId": "9c021290-d827-445c-df64-a3f4257a9562"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5d0f4e76-ec47-4775-8525-f982929f1d81\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5d0f4e76-ec47-4775-8525-f982929f1d81\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving multimodal_only_samples.zip to multimodal_only_samples.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Upload your multimodal_only_samples.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"multimodal_only_samples.zip\"  # Replace with your actual file name if different\n",
        "extract_path = \"/content/fakeddit_data\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Unzipped files:\")\n",
        "os.listdir(extract_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYWsDJrF1kCa",
        "outputId": "d8231391-4be4-4c56-be7d-e5dcfce4fbe2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipped files:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['multimodal_only_samples']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Update path to the correct directory\n",
        "train_df = pd.read_csv('/content/fakeddit_data/multimodal_only_samples/multimodal_train.tsv', sep='\\t')\n",
        "val_df = pd.read_csv('/content/fakeddit_data/multimodal_only_samples/multimodal_validate.tsv', sep='\\t')\n",
        "test_df = pd.read_csv('/content/fakeddit_data/multimodal_only_samples/multimodal_test_public.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "HhWbumyP6QKA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"clean_title\", \"image_url\", \"2_way_label\"]\n",
        "train_df = train_df[columns].dropna()\n",
        "val_df   = val_df[columns].dropna()\n",
        "test_df  = test_df[columns].dropna()"
      ],
      "metadata": {
        "id": "J4JaoMq2Eo4F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df in [train_df, val_df, test_df]:\n",
        "    df.rename(columns={\"clean_title\": \"text\", \"image_url\": \"image_url\", \"2_way_label\": \"label\"}, inplace=True)"
      ],
      "metadata": {
        "id": "Dw2ZNMU-FRFu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ootg-sJSLOlC",
        "outputId": "d13096c0-bd81-4452-a0cf-eaf13149c342"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  my walgreens offbrand mucinex was engraved wit...   \n",
              "1                this concerned sink with a tiny hat   \n",
              "2      hackers leak emails from uae ambassador to us   \n",
              "3                           puppy taking in the view   \n",
              "4               i found a face in my sheet music too   \n",
              "\n",
              "                                           image_url  label  \n",
              "0  https://external-preview.redd.it/WylDbZrnbvZdB...      1  \n",
              "1  https://preview.redd.it/wsfx0gp0f5h11.jpg?widt...      0  \n",
              "2  https://external-preview.redd.it/6fNhdbc6K1vFA...      1  \n",
              "3  https://external-preview.redd.it/HLtVNhTR6wtYt...      1  \n",
              "4  https://preview.redd.it/ri7ut2wn8kv01.jpg?widt...      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7bab09e-d306-427b-a188-6769bf6a5b56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>image_url</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
              "      <td>https://external-preview.redd.it/WylDbZrnbvZdB...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this concerned sink with a tiny hat</td>\n",
              "      <td>https://preview.redd.it/wsfx0gp0f5h11.jpg?widt...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hackers leak emails from uae ambassador to us</td>\n",
              "      <td>https://external-preview.redd.it/6fNhdbc6K1vFA...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>puppy taking in the view</td>\n",
              "      <td>https://external-preview.redd.it/HLtVNhTR6wtYt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i found a face in my sheet music too</td>\n",
              "      <td>https://preview.redd.it/ri7ut2wn8kv01.jpg?widt...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7bab09e-d306-427b-a188-6769bf6a5b56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7bab09e-d306-427b-a188-6769bf6a5b56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7bab09e-d306-427b-a188-6769bf6a5b56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8a48f4e7-9854-4781-930a-508760fcf79d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a48f4e7-9854-4781-930a-508760fcf79d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8a48f4e7-9854-4781-930a-508760fcf79d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print original dataset sizes\n",
        "print(\"Original dataset sizes:\")\n",
        "print(f\"Training samples:   {len(train_df)}\")\n",
        "print(f\"Validation samples: {len(val_df)}\")\n",
        "print(f\"Test samples:       {len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgLzAtaxO6oc",
        "outputId": "572663c7-f2c9-4057-804c-d2e96388affb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset sizes:\n",
            "Training samples:   562466\n",
            "Validation samples: 59169\n",
            "Test samples:       59163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.sample(n=5000, random_state=42)\n",
        "val_df = val_df.sample(n=1000, random_state=42)\n",
        "test_df = test_df.sample(n=1000, random_state=42)"
      ],
      "metadata": {
        "id": "k673se9WopUv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "eeLgajefuO-0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nilf3h9dZzL2",
        "outputId": "31754c08-519f-4a9f-8818-22b0d7425408"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-6ehxi9og\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-6ehxi9og\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->clip==1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=bc2a9eec84ca4c3c87ee22cb8b922fff65c6ea6c3f783e89b90536dabf7df41f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g77bie8m/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
            "Successfully built clip\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, clip\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed clip-1.0 ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import clip\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")  # or another model\n",
        "\n",
        "class FakedditURLDataset(Dataset):\n",
        "    def __init__(self, dataframe, preprocess):\n",
        "        self.df = dataframe\n",
        "        self.preprocess = preprocess\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        url = row[\"image_url\"]\n",
        "        text = row[\"text\"]\n",
        "        label = int(row[\"label\"])\n",
        "\n",
        "        # Load image from URL\n",
        "        try:\n",
        "            response = requests.get(url, timeout=5)\n",
        "            image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "            image = self.preprocess(image)\n",
        "        except:\n",
        "            # Use a blank image if load fails\n",
        "            image = Image.new(\"RGB\", (224, 224), (255, 255, 255))\n",
        "            image = self.preprocess(image)\n",
        "\n",
        "        try:\n",
        "            if len(text.split()) > 75:\n",
        "                summary = summarizer(text, max_length=60, min_length=30, do_sample=False)[0][\"summary_text\"]\n",
        "            else:\n",
        "                summary = text\n",
        "        except Exception as e:\n",
        "            print(f\"Summarization failed for sample {idx}: {e}\")\n",
        "            summary = text[:300]  # fallback\n",
        "\n",
        "        tokenized_text = clip.tokenize([summary], truncate=True)[0]\n",
        "\n",
        "        return image, tokenized_text, torch.tensor(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "a588ebdca46a434aaae91c40637ef540",
            "bd515aa54fa9406986e33befda6fe564",
            "d2b1c565b9b147a9ad175ea26afa556e",
            "617504ef856c495e9499d76c6e053dde",
            "9eb1c54014124877ba398db43e202516",
            "3f7d9eea7f044f81a542a89c087b6518",
            "ca5c635e6dd549c8b3cde8dd97472148",
            "dc0b4e70547040b3a4689bebcf2f56d6",
            "538eeb4f66524c1bbf70de73b8308597",
            "cce6bdb51c5c4d6cb56df3d4602639f8",
            "df0f08b504cd4487b7fc768878ac0c4d",
            "eb4e98d8609941c48cb9aefd11233f23",
            "df148068c59e4551a7d39b4fb3e2538a",
            "49332686f85b4e6aa0e10aaed6a85989",
            "e052adf591d14ba5ab5298eeb5b01339",
            "913e0c7cf9fb4741baa594d83fadd6d8",
            "6e3e95a94d5e46dd934dd46c1d3e5efd",
            "7304e9bda7584e3c9127251e6cb9ac9b",
            "93fdde6d32b24402bee1978b7e44f62c",
            "a412f158bafc4d08899a097d10351f2c",
            "b4ed72e9d5754cc6984717b2b3b8aeba",
            "7426c5ba983b4354b4f2f748827243ce",
            "7e63d3fb24a641bea6dde2de0c203a51",
            "ab3bac98397640d19cf50e1d6911976a",
            "9a14358b6f0041bda7f5e8e5a568317d",
            "6e290ec4e6244c699b60e5c799c4af64",
            "22a1e600820e4bcbb86fa697c398bb27",
            "2553e9c03fa84ecd8e5dff5fa76e9d7a",
            "7984576269214f7d95c5fe2534f2bde9",
            "a5cf9f548dcb41e7a307bf52e84d33b8",
            "5c351fde66fd4f769a82817c2a759067",
            "600f553b686d45ff9835208ee90fa130",
            "9e6b2e639efb4f578ccfd8cd8d396be7",
            "5d682ecf8ca7491d9b5a1fdad6dfc0b5",
            "be7a9b82a8c04b1f9052db947f16fbb9",
            "03e98aa3612a442f8aacb93455e3d76c",
            "69e68593d12e4af484fde0a3bc2c55b7",
            "6c797f3c633a4c669dfa85e6522525b2",
            "474f0c8236d949d693cbe924817f32af",
            "f9044a6cd43249369871b731cf8c3660",
            "dd250f3646b74cd8876dfff55762f8a7",
            "e1b1449ed86c490e8b6836c784223107",
            "949e2cdadd93465bba89699c5d3c91b8",
            "4c439f422e6c4ac2bff16890623714d7",
            "d4eecfb355b14983add3dfbee95f8e96",
            "b8ad12c2f5b24e03888f5db967b28801",
            "f4d78394b40145239236189376c5a2bb",
            "b5ccbb0f4e3f4115a8f56b003d054eae",
            "816b400dd98044db95d8989ededd3f0f",
            "bef8ce29a3c946d2b142d7cfed24e35c",
            "4a63f80b046a461aa3f3de1b73ee34a2",
            "4f80c07e487d4efba62a8370124265f6",
            "3208064469ce4a6fa9eaaf17a5273957",
            "491c5291c7504e7792e1c59fe58e7761",
            "5265b47645264b10ad45093234ed93bc",
            "a2eee307c539461ab77b583666438b14",
            "c0c4c147e6d0472084799a5358313cea",
            "3c7223b39d874c9cb7b0589f40ef317a",
            "faf2bb23de324a1593a19c792e7ac2a7",
            "95f126f0ba16470fa61ab14ffd03eccf",
            "09ca7b0564474f24ab6f790098d60630",
            "a55533a6276d4a0eb429463ab48fdabd",
            "701b443a92db427db9e7b076de57d60b",
            "c20f7cd5d8cc496bb127770886a784c4",
            "e6255087c93b4d0fa2fbbca815c651d6",
            "371c7f1e1e214a6b936ea792c529498e"
          ]
        },
        "id": "dt8XkJFFMAA_",
        "outputId": "904694b1-a52e-4d63-c7d6-8914bad784b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a588ebdca46a434aaae91c40637ef540"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb4e98d8609941c48cb9aefd11233f23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e63d3fb24a641bea6dde2de0c203a51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d682ecf8ca7491d9b5a1fdad6dfc0b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4eecfb355b14983add3dfbee95f8e96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2eee307c539461ab77b583666438b14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "train_dataset = FakedditURLDataset(train_df, preprocess)\n",
        "val_dataset   = FakedditURLDataset(val_df, preprocess)\n",
        "test_dataset  = FakedditURLDataset(test_df, preprocess)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=128)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHG7YJqtLQa-",
        "outputId": "65d73ba6-1663-428a-dea2-ceb911a2bd62"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:11<00:00, 31.8MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "D-p0-19AMjZn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FakeNewsClassifier(nn.Module):\n",
        "    def __init__(self, embed_dim=512):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 2)  # Binary output\n",
        "        )\n",
        "\n",
        "    def forward(self, image_feat, text_feat):\n",
        "        x = torch.cat((image_feat, text_feat), dim=1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "Q58TdhMpMxRt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
        "print(f\"Number of batches in val_loader: {len(val_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWnvurgcNrik",
        "outputId": "8aa6134d-30c7-4c09-9be9-fdd6ff844afd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches in train_loader: 40\n",
            "Number of batches in val_loader: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeMQUtaJN8iR",
        "outputId": "f35529da-2d72-4f82-9ff2-1255ef12b557"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "model = FakeNewsClassifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
        "\n",
        "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(5):  # Change epochs as needed\n",
        "    print(f\"\\n=== Epoch {epoch+1} ===\")\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # tqdm progress bar wrapper\n",
        "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "    for batch_idx, (images, texts, labels) in progress_bar:\n",
        "        print(f\"\\nBatch {batch_idx+1}\")\n",
        "\n",
        "        # Check batch contents\n",
        "        print(\"Raw batch shapes:\")\n",
        "        print(\"Images:\", images.shape)\n",
        "        print(\"Texts:\", texts.shape)\n",
        "        print(\"Labels:\", labels.shape)\n",
        "\n",
        "        images, texts, labels = images.to(device), texts.to(device), labels.to(device)\n",
        "        print(\"Moved batch to device\")\n",
        "\n",
        "        # Extract features using CLIP\n",
        "        with torch.no_grad():\n",
        "            print(\"Encoding image features...\")\n",
        "            image_features = clip_model.encode_image(images).float()\n",
        "            print(\"Encoding text features...\")\n",
        "            text_features = clip_model.encode_text(texts).float()\n",
        "            print(\"Image features:\", image_features.shape)\n",
        "            print(\"Text features:\", text_features.shape)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(image_features, text_features)\n",
        "\n",
        "        # Check output shapes for debugging\n",
        "        print(f\"Outputs shape: {outputs.shape}, Labels shape: {labels.shape}\")\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        print(f\"Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # Accuracy calculation\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        epoch_accuracy = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1} Complete - Avg Loss = {avg_loss:.4f} - Accuracy = {epoch_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRSCumzNOMzs",
        "outputId": "3f2b2818-4dcc-43ba-85dd-f33371d5fbe2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Number of batches in train_loader: 40\n",
            "\n",
            "=== Epoch 1 ===\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 1:   0%|          | 0/40 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Batch 1\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   2%|▎         | 1/40 [00:40<26:18, 40.47s/it, loss=0.698]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.6982\n",
            "Epoch 1 Complete - Avg Loss = 0.0175 - Accuracy = 43.75%\n",
            "\n",
            "Batch 2\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   5%|▌         | 2/40 [01:18<24:41, 39.00s/it, loss=0.684]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.6838\n",
            "Epoch 1 Complete - Avg Loss = 0.0346 - Accuracy = 50.78%\n",
            "\n",
            "Batch 3\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   8%|▊         | 3/40 [01:51<22:26, 36.39s/it, loss=0.671]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.6705\n",
            "Epoch 1 Complete - Avg Loss = 0.0513 - Accuracy = 52.86%\n",
            "\n",
            "Batch 4\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  10%|█         | 4/40 [02:25<21:15, 35.42s/it, loss=0.647]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.6473\n",
            "Epoch 1 Complete - Avg Loss = 0.0675 - Accuracy = 55.27%\n",
            "\n",
            "Batch 5\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  12%|█▎        | 5/40 [02:59<20:14, 34.69s/it, loss=0.632]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.6319\n",
            "Epoch 1 Complete - Avg Loss = 0.0833 - Accuracy = 56.88%\n",
            "\n",
            "Batch 6\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  15%|█▌        | 6/40 [03:33<19:32, 34.49s/it, loss=0.62]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.6202\n",
            "Epoch 1 Complete - Avg Loss = 0.0988 - Accuracy = 58.85%\n",
            "\n",
            "Batch 7\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  18%|█▊        | 7/40 [04:08<19:08, 34.79s/it, loss=0.601]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.6013\n",
            "Epoch 1 Complete - Avg Loss = 0.1138 - Accuracy = 59.49%\n",
            "\n",
            "Batch 8\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  20%|██        | 8/40 [04:52<20:03, 37.62s/it, loss=0.586]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.5860\n",
            "Epoch 1 Complete - Avg Loss = 0.1285 - Accuracy = 60.16%\n",
            "\n",
            "Batch 9\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  22%|██▎       | 9/40 [05:29<19:20, 37.43s/it, loss=0.607]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.6075\n",
            "Epoch 1 Complete - Avg Loss = 0.1437 - Accuracy = 59.81%\n",
            "\n",
            "Batch 10\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  25%|██▌       | 10/40 [06:05<18:36, 37.21s/it, loss=0.598]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.5979\n",
            "Epoch 1 Complete - Avg Loss = 0.1586 - Accuracy = 59.61%\n",
            "\n",
            "Batch 11\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  28%|██▊       | 11/40 [06:42<17:53, 37.01s/it, loss=0.523]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.5228\n",
            "Epoch 1 Complete - Avg Loss = 0.1717 - Accuracy = 60.23%\n",
            "\n",
            "Batch 12\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  30%|███       | 12/40 [07:16<16:53, 36.18s/it, loss=0.574]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.5741\n",
            "Epoch 1 Complete - Avg Loss = 0.1860 - Accuracy = 60.61%\n",
            "\n",
            "Batch 13\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  32%|███▎      | 13/40 [07:50<15:56, 35.44s/it, loss=0.53]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.5296\n",
            "Epoch 1 Complete - Avg Loss = 0.1993 - Accuracy = 60.76%\n",
            "\n",
            "Batch 14\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  35%|███▌      | 14/40 [08:24<15:11, 35.06s/it, loss=0.534]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.5341\n",
            "Epoch 1 Complete - Avg Loss = 0.2126 - Accuracy = 61.38%\n",
            "\n",
            "Batch 15\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  38%|███▊      | 15/40 [09:00<14:39, 35.18s/it, loss=0.56]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.5595\n",
            "Epoch 1 Complete - Avg Loss = 0.2266 - Accuracy = 61.46%\n",
            "\n",
            "Batch 16\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  40%|████      | 16/40 [09:34<13:57, 34.91s/it, loss=0.529]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.5291\n",
            "Epoch 1 Complete - Avg Loss = 0.2398 - Accuracy = 61.72%\n",
            "\n",
            "Batch 17\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  42%|████▎     | 17/40 [10:09<13:25, 35.00s/it, loss=0.488]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4876\n",
            "Epoch 1 Complete - Avg Loss = 0.2520 - Accuracy = 62.32%\n",
            "\n",
            "Batch 18\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  45%|████▌     | 18/40 [10:43<12:44, 34.77s/it, loss=0.459]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4594\n",
            "Epoch 1 Complete - Avg Loss = 0.2635 - Accuracy = 63.19%\n",
            "\n",
            "Batch 19\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  48%|████▊     | 19/40 [11:18<12:11, 34.82s/it, loss=0.479]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4789\n",
            "Epoch 1 Complete - Avg Loss = 0.2755 - Accuracy = 63.65%\n",
            "\n",
            "Batch 20\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  50%|█████     | 20/40 [11:52<11:27, 34.40s/it, loss=0.479]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4791\n",
            "Epoch 1 Complete - Avg Loss = 0.2875 - Accuracy = 64.14%\n",
            "\n",
            "Batch 21\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  52%|█████▎    | 21/40 [12:27<10:58, 34.65s/it, loss=0.469]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4688\n",
            "Epoch 1 Complete - Avg Loss = 0.2992 - Accuracy = 64.69%\n",
            "\n",
            "Batch 22\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  55%|█████▌    | 22/40 [13:01<10:22, 34.59s/it, loss=0.456]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4562\n",
            "Epoch 1 Complete - Avg Loss = 0.3106 - Accuracy = 65.13%\n",
            "\n",
            "Batch 23\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  57%|█████▊    | 23/40 [13:36<09:48, 34.61s/it, loss=0.406]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4059\n",
            "Epoch 1 Complete - Avg Loss = 0.3207 - Accuracy = 65.93%\n",
            "\n",
            "Batch 24\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  60%|██████    | 24/40 [14:09<09:07, 34.22s/it, loss=0.472]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4718\n",
            "Epoch 1 Complete - Avg Loss = 0.3325 - Accuracy = 66.37%\n",
            "\n",
            "Batch 25\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  62%|██████▎   | 25/40 [14:45<08:37, 34.49s/it, loss=0.46]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4601\n",
            "Epoch 1 Complete - Avg Loss = 0.3440 - Accuracy = 66.91%\n",
            "\n",
            "Batch 26\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  65%|██████▌   | 26/40 [15:23<08:19, 35.65s/it, loss=0.457]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4567\n",
            "Epoch 1 Complete - Avg Loss = 0.3555 - Accuracy = 67.37%\n",
            "\n",
            "Batch 27\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  68%|██████▊   | 27/40 [16:00<07:48, 36.02s/it, loss=0.431]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4309\n",
            "Epoch 1 Complete - Avg Loss = 0.3662 - Accuracy = 67.97%\n",
            "\n",
            "Batch 28\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  70%|███████   | 28/40 [16:35<07:09, 35.75s/it, loss=0.393]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3932\n",
            "Epoch 1 Complete - Avg Loss = 0.3761 - Accuracy = 68.50%\n",
            "\n",
            "Batch 29\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  72%|███████▎  | 29/40 [17:09<06:28, 35.29s/it, loss=0.451]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4509\n",
            "Epoch 1 Complete - Avg Loss = 0.3873 - Accuracy = 68.75%\n",
            "\n",
            "Batch 30\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  75%|███████▌  | 30/40 [17:45<05:55, 35.58s/it, loss=0.422]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4224\n",
            "Epoch 1 Complete - Avg Loss = 0.3979 - Accuracy = 69.30%\n",
            "\n",
            "Batch 31\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  78%|███████▊  | 31/40 [18:20<05:16, 35.21s/it, loss=0.452]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4516\n",
            "Epoch 1 Complete - Avg Loss = 0.4092 - Accuracy = 69.53%\n",
            "\n",
            "Batch 32\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  80%|████████  | 32/40 [18:56<04:44, 35.52s/it, loss=0.401]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4010\n",
            "Epoch 1 Complete - Avg Loss = 0.4192 - Accuracy = 70.02%\n",
            "\n",
            "Batch 33\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  82%|████████▎ | 33/40 [19:32<04:09, 35.60s/it, loss=0.401]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4009\n",
            "Epoch 1 Complete - Avg Loss = 0.4292 - Accuracy = 70.45%\n",
            "\n",
            "Batch 34\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  85%|████████▌ | 34/40 [20:06<03:31, 35.30s/it, loss=0.369]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3689\n",
            "Epoch 1 Complete - Avg Loss = 0.4385 - Accuracy = 70.80%\n",
            "\n",
            "Batch 35\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  88%|████████▊ | 35/40 [20:42<02:57, 35.47s/it, loss=0.428]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4276\n",
            "Epoch 1 Complete - Avg Loss = 0.4491 - Accuracy = 71.07%\n",
            "\n",
            "Batch 36\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  90%|█████████ | 36/40 [21:18<02:21, 35.43s/it, loss=0.46]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4598\n",
            "Epoch 1 Complete - Avg Loss = 0.4606 - Accuracy = 71.29%\n",
            "\n",
            "Batch 37\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  92%|█████████▎| 37/40 [21:54<01:47, 35.75s/it, loss=0.422]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4222\n",
            "Epoch 1 Complete - Avg Loss = 0.4712 - Accuracy = 71.60%\n",
            "\n",
            "Batch 38\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  95%|█████████▌| 38/40 [22:36<01:15, 37.57s/it, loss=0.39]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3903\n",
            "Epoch 1 Complete - Avg Loss = 0.4809 - Accuracy = 71.79%\n",
            "\n",
            "Batch 39\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  98%|█████████▊| 39/40 [23:12<00:37, 37.19s/it, loss=0.383]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3828\n",
            "Epoch 1 Complete - Avg Loss = 0.4905 - Accuracy = 72.10%\n",
            "\n",
            "Batch 40\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([8, 3, 224, 224])\n",
            "Texts: torch.Size([8, 77])\n",
            "Labels: torch.Size([8])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 40/40 [23:14<00:00, 34.87s/it, loss=0.434]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([8, 512])\n",
            "Text features: torch.Size([8, 512])\n",
            "Outputs shape: torch.Size([8, 2]), Labels shape: torch.Size([8])\n",
            "Loss: 0.4342\n",
            "Epoch 1 Complete - Avg Loss = 0.5014 - Accuracy = 72.10%\n",
            "\n",
            "=== Epoch 2 ===\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 2:   0%|          | 0/40 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Batch 1\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:   2%|▎         | 1/40 [00:33<21:50, 33.61s/it, loss=0.382]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3824\n",
            "Epoch 2 Complete - Avg Loss = 0.0096 - Accuracy = 81.25%\n",
            "\n",
            "Batch 2\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:   5%|▌         | 2/40 [01:09<22:15, 35.13s/it, loss=0.35]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3505\n",
            "Epoch 2 Complete - Avg Loss = 0.0183 - Accuracy = 82.42%\n",
            "\n",
            "Batch 3\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:   8%|▊         | 3/40 [01:43<21:23, 34.70s/it, loss=0.312]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3122\n",
            "Epoch 2 Complete - Avg Loss = 0.0261 - Accuracy = 85.16%\n",
            "\n",
            "Batch 4\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  10%|█         | 4/40 [02:21<21:34, 35.95s/it, loss=0.327]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3273\n",
            "Epoch 2 Complete - Avg Loss = 0.0343 - Accuracy = 85.74%\n",
            "\n",
            "Batch 5\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  12%|█▎        | 5/40 [02:55<20:27, 35.06s/it, loss=0.327]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3268\n",
            "Epoch 2 Complete - Avg Loss = 0.0425 - Accuracy = 86.25%\n",
            "\n",
            "Batch 6\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  15%|█▌        | 6/40 [03:29<19:40, 34.73s/it, loss=0.358]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3576\n",
            "Epoch 2 Complete - Avg Loss = 0.0514 - Accuracy = 86.07%\n",
            "\n",
            "Batch 7\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  18%|█▊        | 7/40 [04:02<18:48, 34.20s/it, loss=0.321]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3207\n",
            "Epoch 2 Complete - Avg Loss = 0.0594 - Accuracy = 86.16%\n",
            "\n",
            "Batch 8\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  20%|██        | 8/40 [04:36<18:11, 34.11s/it, loss=0.309]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3092\n",
            "Epoch 2 Complete - Avg Loss = 0.0672 - Accuracy = 86.62%\n",
            "\n",
            "Batch 9\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  22%|██▎       | 9/40 [05:09<17:28, 33.81s/it, loss=0.325]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3246\n",
            "Epoch 2 Complete - Avg Loss = 0.0753 - Accuracy = 86.72%\n",
            "\n",
            "Batch 10\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  25%|██▌       | 10/40 [05:43<16:51, 33.72s/it, loss=0.372]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3721\n",
            "Epoch 2 Complete - Avg Loss = 0.0846 - Accuracy = 86.48%\n",
            "\n",
            "Batch 11\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  28%|██▊       | 11/40 [06:17<16:20, 33.80s/it, loss=0.353]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3531\n",
            "Epoch 2 Complete - Avg Loss = 0.0934 - Accuracy = 86.01%\n",
            "\n",
            "Batch 12\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  30%|███       | 12/40 [06:51<15:53, 34.04s/it, loss=0.361]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3615\n",
            "Epoch 2 Complete - Avg Loss = 0.1024 - Accuracy = 85.87%\n",
            "\n",
            "Batch 13\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  32%|███▎      | 13/40 [07:25<15:17, 33.99s/it, loss=0.313]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3135\n",
            "Epoch 2 Complete - Avg Loss = 0.1103 - Accuracy = 86.06%\n",
            "\n",
            "Batch 14\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  35%|███▌      | 14/40 [08:01<15:00, 34.63s/it, loss=0.286]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2865\n",
            "Epoch 2 Complete - Avg Loss = 0.1174 - Accuracy = 86.22%\n",
            "\n",
            "Batch 15\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  38%|███▊      | 15/40 [08:38<14:39, 35.16s/it, loss=0.317]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3169\n",
            "Epoch 2 Complete - Avg Loss = 0.1254 - Accuracy = 86.09%\n",
            "\n",
            "Batch 16\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  40%|████      | 16/40 [09:11<13:54, 34.75s/it, loss=0.292]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2921\n",
            "Epoch 2 Complete - Avg Loss = 0.1327 - Accuracy = 86.28%\n",
            "\n",
            "Batch 17\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  42%|████▎     | 17/40 [09:47<13:22, 34.90s/it, loss=0.343]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3429\n",
            "Epoch 2 Complete - Avg Loss = 0.1412 - Accuracy = 86.35%\n",
            "\n",
            "Batch 18\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  45%|████▌     | 18/40 [10:22<12:48, 34.95s/it, loss=0.325]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3254\n",
            "Epoch 2 Complete - Avg Loss = 0.1494 - Accuracy = 86.11%\n",
            "\n",
            "Batch 19\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  48%|████▊     | 19/40 [10:54<11:55, 34.08s/it, loss=0.384]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3842\n",
            "Epoch 2 Complete - Avg Loss = 0.1590 - Accuracy = 85.98%\n",
            "\n",
            "Batch 20\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  50%|█████     | 20/40 [11:27<11:18, 33.94s/it, loss=0.369]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3691\n",
            "Epoch 2 Complete - Avg Loss = 0.1682 - Accuracy = 85.82%\n",
            "\n",
            "Batch 21\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  52%|█████▎    | 21/40 [12:01<10:40, 33.71s/it, loss=0.282]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2823\n",
            "Epoch 2 Complete - Avg Loss = 0.1753 - Accuracy = 85.94%\n",
            "\n",
            "Batch 22\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  55%|█████▌    | 22/40 [12:37<10:18, 34.39s/it, loss=0.245]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2447\n",
            "Epoch 2 Complete - Avg Loss = 0.1814 - Accuracy = 86.19%\n",
            "\n",
            "Batch 23\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  57%|█████▊    | 23/40 [13:10<09:40, 34.17s/it, loss=0.261]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2605\n",
            "Epoch 2 Complete - Avg Loss = 0.1879 - Accuracy = 86.35%\n",
            "\n",
            "Batch 24\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  60%|██████    | 24/40 [13:44<09:06, 34.17s/it, loss=0.335]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3351\n",
            "Epoch 2 Complete - Avg Loss = 0.1963 - Accuracy = 86.23%\n",
            "\n",
            "Batch 25\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  62%|██████▎   | 25/40 [14:18<08:29, 33.95s/it, loss=0.372]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3725\n",
            "Epoch 2 Complete - Avg Loss = 0.2056 - Accuracy = 86.03%\n",
            "\n",
            "Batch 26\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  65%|██████▌   | 26/40 [14:52<07:55, 34.00s/it, loss=0.3]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2999\n",
            "Epoch 2 Complete - Avg Loss = 0.2131 - Accuracy = 86.00%\n",
            "\n",
            "Batch 27\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  68%|██████▊   | 27/40 [15:27<07:24, 34.19s/it, loss=0.369]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3686\n",
            "Epoch 2 Complete - Avg Loss = 0.2223 - Accuracy = 85.82%\n",
            "\n",
            "Batch 28\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  70%|███████   | 28/40 [16:01<06:51, 34.27s/it, loss=0.235]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2351\n",
            "Epoch 2 Complete - Avg Loss = 0.2282 - Accuracy = 85.99%\n",
            "\n",
            "Batch 29\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  72%|███████▎  | 29/40 [16:35<06:17, 34.27s/it, loss=0.319]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3186\n",
            "Epoch 2 Complete - Avg Loss = 0.2361 - Accuracy = 86.02%\n",
            "\n",
            "Batch 30\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  75%|███████▌  | 30/40 [17:09<05:42, 34.21s/it, loss=0.297]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2974\n",
            "Epoch 2 Complete - Avg Loss = 0.2436 - Accuracy = 85.96%\n",
            "\n",
            "Batch 31\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  78%|███████▊  | 31/40 [17:43<05:07, 34.13s/it, loss=0.365]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3649\n",
            "Epoch 2 Complete - Avg Loss = 0.2527 - Accuracy = 85.94%\n",
            "\n",
            "Batch 32\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  80%|████████  | 32/40 [18:18<04:34, 34.25s/it, loss=0.281]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2813\n",
            "Epoch 2 Complete - Avg Loss = 0.2597 - Accuracy = 86.06%\n",
            "\n",
            "Batch 33\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  82%|████████▎ | 33/40 [18:52<03:59, 34.26s/it, loss=0.336]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3360\n",
            "Epoch 2 Complete - Avg Loss = 0.2681 - Accuracy = 86.03%\n",
            "\n",
            "Batch 34\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  85%|████████▌ | 34/40 [19:26<03:24, 34.16s/it, loss=0.25]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2498\n",
            "Epoch 2 Complete - Avg Loss = 0.2744 - Accuracy = 86.12%\n",
            "\n",
            "Batch 35\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  88%|████████▊ | 35/40 [20:00<02:50, 34.08s/it, loss=0.38]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3804\n",
            "Epoch 2 Complete - Avg Loss = 0.2839 - Accuracy = 86.00%\n",
            "\n",
            "Batch 36\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  90%|█████████ | 36/40 [20:34<02:16, 34.09s/it, loss=0.304]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3045\n",
            "Epoch 2 Complete - Avg Loss = 0.2915 - Accuracy = 86.09%\n",
            "\n",
            "Batch 37\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  92%|█████████▎| 37/40 [21:07<01:41, 33.87s/it, loss=0.294]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2944\n",
            "Epoch 2 Complete - Avg Loss = 0.2989 - Accuracy = 86.11%\n",
            "\n",
            "Batch 38\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  95%|█████████▌| 38/40 [21:42<01:08, 34.05s/it, loss=0.295]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2954\n",
            "Epoch 2 Complete - Avg Loss = 0.3062 - Accuracy = 86.16%\n",
            "\n",
            "Batch 39\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  98%|█████████▊| 39/40 [22:16<00:33, 33.97s/it, loss=0.361]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3606\n",
            "Epoch 2 Complete - Avg Loss = 0.3153 - Accuracy = 86.08%\n",
            "\n",
            "Batch 40\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([8, 3, 224, 224])\n",
            "Texts: torch.Size([8, 77])\n",
            "Labels: torch.Size([8])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 40/40 [22:18<00:00, 33.46s/it, loss=0.441]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([8, 512])\n",
            "Text features: torch.Size([8, 512])\n",
            "Outputs shape: torch.Size([8, 2]), Labels shape: torch.Size([8])\n",
            "Loss: 0.4412\n",
            "Epoch 2 Complete - Avg Loss = 0.3263 - Accuracy = 86.04%\n",
            "\n",
            "=== Epoch 3 ===\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 3:   0%|          | 0/40 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Batch 1\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:   2%|▎         | 1/40 [00:33<21:36, 33.24s/it, loss=0.239]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2390\n",
            "Epoch 3 Complete - Avg Loss = 0.0060 - Accuracy = 89.84%\n",
            "\n",
            "Batch 2\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:   5%|▌         | 2/40 [01:06<21:14, 33.53s/it, loss=0.228]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2279\n",
            "Epoch 3 Complete - Avg Loss = 0.0117 - Accuracy = 90.23%\n",
            "\n",
            "Batch 3\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:   8%|▊         | 3/40 [01:42<21:15, 34.48s/it, loss=0.266]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2656\n",
            "Epoch 3 Complete - Avg Loss = 0.0183 - Accuracy = 89.58%\n",
            "\n",
            "Batch 4\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  10%|█         | 4/40 [02:17<20:54, 34.84s/it, loss=0.256]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2560\n",
            "Epoch 3 Complete - Avg Loss = 0.0247 - Accuracy = 89.45%\n",
            "\n",
            "Batch 5\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  12%|█▎        | 5/40 [02:51<20:00, 34.31s/it, loss=0.238]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2376\n",
            "Epoch 3 Complete - Avg Loss = 0.0306 - Accuracy = 89.38%\n",
            "\n",
            "Batch 6\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  15%|█▌        | 6/40 [03:25<19:20, 34.13s/it, loss=0.256]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2557\n",
            "Epoch 3 Complete - Avg Loss = 0.0370 - Accuracy = 89.45%\n",
            "\n",
            "Batch 7\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  18%|█▊        | 7/40 [03:59<18:51, 34.28s/it, loss=0.371]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3707\n",
            "Epoch 3 Complete - Avg Loss = 0.0463 - Accuracy = 88.62%\n",
            "\n",
            "Batch 8\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  20%|██        | 8/40 [04:33<18:09, 34.06s/it, loss=0.376]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3763\n",
            "Epoch 3 Complete - Avg Loss = 0.0557 - Accuracy = 87.79%\n",
            "\n",
            "Batch 9\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  22%|██▎       | 9/40 [05:06<17:32, 33.94s/it, loss=0.249]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2488\n",
            "Epoch 3 Complete - Avg Loss = 0.0619 - Accuracy = 87.93%\n",
            "\n",
            "Batch 10\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  25%|██▌       | 10/40 [05:41<17:03, 34.11s/it, loss=0.193]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1933\n",
            "Epoch 3 Complete - Avg Loss = 0.0668 - Accuracy = 88.52%\n",
            "\n",
            "Batch 11\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  28%|██▊       | 11/40 [06:16<16:34, 34.29s/it, loss=0.295]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2948\n",
            "Epoch 3 Complete - Avg Loss = 0.0741 - Accuracy = 88.49%\n",
            "\n",
            "Batch 12\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  30%|███       | 12/40 [06:50<16:03, 34.39s/it, loss=0.163]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1630\n",
            "Epoch 3 Complete - Avg Loss = 0.0782 - Accuracy = 88.87%\n",
            "\n",
            "Batch 13\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  32%|███▎      | 13/40 [07:23<15:18, 34.00s/it, loss=0.244]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2440\n",
            "Epoch 3 Complete - Avg Loss = 0.0843 - Accuracy = 89.00%\n",
            "\n",
            "Batch 14\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  35%|███▌      | 14/40 [07:57<14:41, 33.89s/it, loss=0.208]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2080\n",
            "Epoch 3 Complete - Avg Loss = 0.0895 - Accuracy = 89.29%\n",
            "\n",
            "Batch 15\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  38%|███▊      | 15/40 [08:30<13:59, 33.59s/it, loss=0.297]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2975\n",
            "Epoch 3 Complete - Avg Loss = 0.0970 - Accuracy = 89.43%\n",
            "\n",
            "Batch 16\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  40%|████      | 16/40 [09:04<13:26, 33.59s/it, loss=0.247]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2467\n",
            "Epoch 3 Complete - Avg Loss = 0.1031 - Accuracy = 89.40%\n",
            "\n",
            "Batch 17\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  42%|████▎     | 17/40 [09:37<12:54, 33.66s/it, loss=0.273]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2734\n",
            "Epoch 3 Complete - Avg Loss = 0.1100 - Accuracy = 89.29%\n",
            "\n",
            "Batch 18\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  45%|████▌     | 18/40 [10:11<12:21, 33.69s/it, loss=0.277]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2770\n",
            "Epoch 3 Complete - Avg Loss = 0.1169 - Accuracy = 89.15%\n",
            "\n",
            "Batch 19\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  48%|████▊     | 19/40 [10:45<11:49, 33.77s/it, loss=0.36]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3599\n",
            "Epoch 3 Complete - Avg Loss = 0.1259 - Accuracy = 88.77%\n",
            "\n",
            "Batch 20\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  50%|█████     | 20/40 [11:19<11:17, 33.87s/it, loss=0.273]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2734\n",
            "Epoch 3 Complete - Avg Loss = 0.1327 - Accuracy = 88.75%\n",
            "\n",
            "Batch 21\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  52%|█████▎    | 21/40 [11:53<10:40, 33.72s/it, loss=0.256]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2556\n",
            "Epoch 3 Complete - Avg Loss = 0.1391 - Accuracy = 88.76%\n",
            "\n",
            "Batch 22\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  55%|█████▌    | 22/40 [12:27<10:09, 33.88s/it, loss=0.238]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2382\n",
            "Epoch 3 Complete - Avg Loss = 0.1451 - Accuracy = 88.96%\n",
            "\n",
            "Batch 23\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  57%|█████▊    | 23/40 [13:01<09:36, 33.93s/it, loss=0.156]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1565\n",
            "Epoch 3 Complete - Avg Loss = 0.1490 - Accuracy = 89.27%\n",
            "\n",
            "Batch 24\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  60%|██████    | 24/40 [13:35<09:06, 34.14s/it, loss=0.21]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2103\n",
            "Epoch 3 Complete - Avg Loss = 0.1542 - Accuracy = 89.39%\n",
            "\n",
            "Batch 25\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  62%|██████▎   | 25/40 [14:08<08:26, 33.79s/it, loss=0.313]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3134\n",
            "Epoch 3 Complete - Avg Loss = 0.1621 - Accuracy = 89.28%\n",
            "\n",
            "Batch 26\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  65%|██████▌   | 26/40 [14:43<07:55, 33.98s/it, loss=0.24]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2404\n",
            "Epoch 3 Complete - Avg Loss = 0.1681 - Accuracy = 89.36%\n",
            "\n",
            "Batch 27\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  68%|██████▊   | 27/40 [15:17<07:22, 34.05s/it, loss=0.257]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2565\n",
            "Epoch 3 Complete - Avg Loss = 0.1745 - Accuracy = 89.38%\n",
            "\n",
            "Batch 28\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  70%|███████   | 28/40 [15:51<06:48, 34.01s/it, loss=0.231]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2313\n",
            "Epoch 3 Complete - Avg Loss = 0.1803 - Accuracy = 89.51%\n",
            "\n",
            "Batch 29\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  72%|███████▎  | 29/40 [16:26<06:17, 34.33s/it, loss=0.213]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2131\n",
            "Epoch 3 Complete - Avg Loss = 0.1856 - Accuracy = 89.52%\n",
            "\n",
            "Batch 30\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  75%|███████▌  | 30/40 [17:01<05:44, 34.42s/it, loss=0.322]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3224\n",
            "Epoch 3 Complete - Avg Loss = 0.1937 - Accuracy = 89.43%\n",
            "\n",
            "Batch 31\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  78%|███████▊  | 31/40 [17:36<05:12, 34.70s/it, loss=0.27]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2704\n",
            "Epoch 3 Complete - Avg Loss = 0.2004 - Accuracy = 89.49%\n",
            "\n",
            "Batch 32\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  80%|████████  | 32/40 [18:10<04:36, 34.54s/it, loss=0.245]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2455\n",
            "Epoch 3 Complete - Avg Loss = 0.2065 - Accuracy = 89.45%\n",
            "\n",
            "Batch 33\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  82%|████████▎ | 33/40 [18:46<04:03, 34.82s/it, loss=0.254]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2537\n",
            "Epoch 3 Complete - Avg Loss = 0.2129 - Accuracy = 89.44%\n",
            "\n",
            "Batch 34\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  85%|████████▌ | 34/40 [19:21<03:29, 34.89s/it, loss=0.281]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2808\n",
            "Epoch 3 Complete - Avg Loss = 0.2199 - Accuracy = 89.45%\n",
            "\n",
            "Batch 35\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  88%|████████▊ | 35/40 [19:55<02:53, 34.74s/it, loss=0.281]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2811\n",
            "Epoch 3 Complete - Avg Loss = 0.2269 - Accuracy = 89.46%\n",
            "\n",
            "Batch 36\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  90%|█████████ | 36/40 [20:29<02:18, 34.51s/it, loss=0.289]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2889\n",
            "Epoch 3 Complete - Avg Loss = 0.2342 - Accuracy = 89.50%\n",
            "\n",
            "Batch 37\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  92%|█████████▎| 37/40 [21:04<01:44, 34.71s/it, loss=0.244]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2436\n",
            "Epoch 3 Complete - Avg Loss = 0.2402 - Accuracy = 89.57%\n",
            "\n",
            "Batch 38\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  95%|█████████▌| 38/40 [21:39<01:09, 34.65s/it, loss=0.406]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.4062\n",
            "Epoch 3 Complete - Avg Loss = 0.2504 - Accuracy = 89.31%\n",
            "\n",
            "Batch 39\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  98%|█████████▊| 39/40 [22:13<00:34, 34.47s/it, loss=0.244]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2437\n",
            "Epoch 3 Complete - Avg Loss = 0.2565 - Accuracy = 89.26%\n",
            "\n",
            "Batch 40\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([8, 3, 224, 224])\n",
            "Texts: torch.Size([8, 77])\n",
            "Labels: torch.Size([8])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 40/40 [22:15<00:00, 33.38s/it, loss=0.0359]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([8, 512])\n",
            "Text features: torch.Size([8, 512])\n",
            "Outputs shape: torch.Size([8, 2]), Labels shape: torch.Size([8])\n",
            "Loss: 0.0359\n",
            "Epoch 3 Complete - Avg Loss = 0.2574 - Accuracy = 89.28%\n",
            "\n",
            "=== Epoch 4 ===\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch 4:   0%|          | 0/40 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Batch 1\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:   2%|▎         | 1/40 [00:34<22:13, 34.20s/it, loss=0.253]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2534\n",
            "Epoch 4 Complete - Avg Loss = 0.0063 - Accuracy = 86.72%\n",
            "\n",
            "Batch 2\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:   5%|▌         | 2/40 [01:08<21:37, 34.14s/it, loss=0.19]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1904\n",
            "Epoch 4 Complete - Avg Loss = 0.0111 - Accuracy = 89.45%\n",
            "\n",
            "Batch 3\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:   8%|▊         | 3/40 [01:42<21:00, 34.06s/it, loss=0.249]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2493\n",
            "Epoch 4 Complete - Avg Loss = 0.0173 - Accuracy = 89.32%\n",
            "\n",
            "Batch 4\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  10%|█         | 4/40 [02:15<20:16, 33.80s/it, loss=0.272]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2724\n",
            "Epoch 4 Complete - Avg Loss = 0.0241 - Accuracy = 89.45%\n",
            "\n",
            "Batch 5\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  12%|█▎        | 5/40 [02:48<19:37, 33.63s/it, loss=0.206]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2063\n",
            "Epoch 4 Complete - Avg Loss = 0.0293 - Accuracy = 90.00%\n",
            "\n",
            "Batch 6\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  15%|█▌        | 6/40 [03:23<19:12, 33.88s/it, loss=0.296]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2965\n",
            "Epoch 4 Complete - Avg Loss = 0.0367 - Accuracy = 89.32%\n",
            "\n",
            "Batch 7\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  18%|█▊        | 7/40 [03:57<18:37, 33.86s/it, loss=0.259]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2587\n",
            "Epoch 4 Complete - Avg Loss = 0.0432 - Accuracy = 89.17%\n",
            "\n",
            "Batch 8\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  20%|██        | 8/40 [04:31<18:05, 33.92s/it, loss=0.286]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2858\n",
            "Epoch 4 Complete - Avg Loss = 0.0503 - Accuracy = 89.45%\n",
            "\n",
            "Batch 9\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  22%|██▎       | 9/40 [05:04<17:25, 33.72s/it, loss=0.247]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2475\n",
            "Epoch 4 Complete - Avg Loss = 0.0565 - Accuracy = 89.50%\n",
            "\n",
            "Batch 10\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  25%|██▌       | 10/40 [05:37<16:46, 33.54s/it, loss=0.166]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1661\n",
            "Epoch 4 Complete - Avg Loss = 0.0607 - Accuracy = 89.92%\n",
            "\n",
            "Batch 11\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  28%|██▊       | 11/40 [06:10<16:07, 33.36s/it, loss=0.22]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2198\n",
            "Epoch 4 Complete - Avg Loss = 0.0662 - Accuracy = 90.13%\n",
            "\n",
            "Batch 12\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  30%|███       | 12/40 [06:44<15:39, 33.57s/it, loss=0.242]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2423\n",
            "Epoch 4 Complete - Avg Loss = 0.0722 - Accuracy = 89.97%\n",
            "\n",
            "Batch 13\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  32%|███▎      | 13/40 [07:18<15:08, 33.67s/it, loss=0.2]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2004\n",
            "Epoch 4 Complete - Avg Loss = 0.0772 - Accuracy = 90.14%\n",
            "\n",
            "Batch 14\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  35%|███▌      | 14/40 [07:52<14:38, 33.80s/it, loss=0.237]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2371\n",
            "Epoch 4 Complete - Avg Loss = 0.0831 - Accuracy = 90.07%\n",
            "\n",
            "Batch 15\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  38%|███▊      | 15/40 [08:26<14:07, 33.90s/it, loss=0.203]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2027\n",
            "Epoch 4 Complete - Avg Loss = 0.0882 - Accuracy = 90.36%\n",
            "\n",
            "Batch 16\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  40%|████      | 16/40 [09:00<13:34, 33.95s/it, loss=0.204]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2039\n",
            "Epoch 4 Complete - Avg Loss = 0.0933 - Accuracy = 90.53%\n",
            "\n",
            "Batch 17\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  42%|████▎     | 17/40 [09:34<12:57, 33.82s/it, loss=0.165]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1654\n",
            "Epoch 4 Complete - Avg Loss = 0.0974 - Accuracy = 90.85%\n",
            "\n",
            "Batch 18\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  45%|████▌     | 18/40 [10:08<12:23, 33.81s/it, loss=0.262]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2616\n",
            "Epoch 4 Complete - Avg Loss = 0.1040 - Accuracy = 90.76%\n",
            "\n",
            "Batch 19\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  48%|████▊     | 19/40 [10:42<11:50, 33.84s/it, loss=0.253]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2526\n",
            "Epoch 4 Complete - Avg Loss = 0.1103 - Accuracy = 90.62%\n",
            "\n",
            "Batch 20\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  50%|█████     | 20/40 [11:15<11:15, 33.77s/it, loss=0.173]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1730\n",
            "Epoch 4 Complete - Avg Loss = 0.1146 - Accuracy = 90.70%\n",
            "\n",
            "Batch 21\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  52%|█████▎    | 21/40 [11:50<10:50, 34.23s/it, loss=0.214]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2143\n",
            "Epoch 4 Complete - Avg Loss = 0.1200 - Accuracy = 90.70%\n",
            "\n",
            "Batch 22\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  55%|█████▌    | 22/40 [12:24<10:13, 34.09s/it, loss=0.303]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3034\n",
            "Epoch 4 Complete - Avg Loss = 0.1276 - Accuracy = 90.52%\n",
            "\n",
            "Batch 23\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  57%|█████▊    | 23/40 [12:57<09:34, 33.81s/it, loss=0.259]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2594\n",
            "Epoch 4 Complete - Avg Loss = 0.1341 - Accuracy = 90.49%\n",
            "\n",
            "Batch 24\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  60%|██████    | 24/40 [13:31<09:00, 33.77s/it, loss=0.305]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3054\n",
            "Epoch 4 Complete - Avg Loss = 0.1417 - Accuracy = 90.40%\n",
            "\n",
            "Batch 25\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  62%|██████▎   | 25/40 [14:09<08:43, 34.87s/it, loss=0.149]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1486\n",
            "Epoch 4 Complete - Avg Loss = 0.1454 - Accuracy = 90.59%\n",
            "\n",
            "Batch 26\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  65%|██████▌   | 26/40 [14:47<08:24, 36.05s/it, loss=0.165]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1653\n",
            "Epoch 4 Complete - Avg Loss = 0.1495 - Accuracy = 90.72%\n",
            "\n",
            "Batch 27\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  68%|██████▊   | 27/40 [15:25<07:53, 36.41s/it, loss=0.265]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2655\n",
            "Epoch 4 Complete - Avg Loss = 0.1562 - Accuracy = 90.65%\n",
            "\n",
            "Batch 28\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  70%|███████   | 28/40 [15:59<07:09, 35.83s/it, loss=0.221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2208\n",
            "Epoch 4 Complete - Avg Loss = 0.1617 - Accuracy = 90.74%\n",
            "\n",
            "Batch 29\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  72%|███████▎  | 29/40 [16:33<06:29, 35.42s/it, loss=0.216]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2160\n",
            "Epoch 4 Complete - Avg Loss = 0.1671 - Accuracy = 90.79%\n",
            "\n",
            "Batch 30\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  75%|███████▌  | 30/40 [17:09<05:53, 35.35s/it, loss=0.172]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1723\n",
            "Epoch 4 Complete - Avg Loss = 0.1714 - Accuracy = 90.89%\n",
            "\n",
            "Batch 31\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  78%|███████▊  | 31/40 [17:42<05:13, 34.85s/it, loss=0.225]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2251\n",
            "Epoch 4 Complete - Avg Loss = 0.1770 - Accuracy = 90.83%\n",
            "\n",
            "Batch 32\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  80%|████████  | 32/40 [18:18<04:40, 35.02s/it, loss=0.217]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2168\n",
            "Epoch 4 Complete - Avg Loss = 0.1825 - Accuracy = 90.84%\n",
            "\n",
            "Batch 33\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  82%|████████▎ | 33/40 [18:52<04:03, 34.72s/it, loss=0.259]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2592\n",
            "Epoch 4 Complete - Avg Loss = 0.1889 - Accuracy = 90.84%\n",
            "\n",
            "Batch 34\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  85%|████████▌ | 34/40 [19:27<03:29, 34.97s/it, loss=0.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2304\n",
            "Epoch 4 Complete - Avg Loss = 0.1947 - Accuracy = 90.88%\n",
            "\n",
            "Batch 35\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  88%|████████▊ | 35/40 [20:01<02:53, 34.68s/it, loss=0.248]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2478\n",
            "Epoch 4 Complete - Avg Loss = 0.2009 - Accuracy = 90.83%\n",
            "\n",
            "Batch 36\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  90%|█████████ | 36/40 [20:36<02:18, 34.66s/it, loss=0.182]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1818\n",
            "Epoch 4 Complete - Avg Loss = 0.2054 - Accuracy = 90.91%\n",
            "\n",
            "Batch 37\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  92%|█████████▎| 37/40 [21:11<01:44, 34.86s/it, loss=0.201]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2007\n",
            "Epoch 4 Complete - Avg Loss = 0.2105 - Accuracy = 90.96%\n",
            "\n",
            "Batch 38\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  95%|█████████▌| 38/40 [21:46<01:09, 34.72s/it, loss=0.194]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1937\n",
            "Epoch 4 Complete - Avg Loss = 0.2153 - Accuracy = 91.04%\n",
            "\n",
            "Batch 39\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4:  98%|█████████▊| 39/40 [22:19<00:34, 34.36s/it, loss=0.236]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2356\n",
            "Epoch 4 Complete - Avg Loss = 0.2212 - Accuracy = 90.99%\n",
            "\n",
            "Batch 40\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([8, 3, 224, 224])\n",
            "Texts: torch.Size([8, 77])\n",
            "Labels: torch.Size([8])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 40/40 [22:21<00:00, 33.55s/it, loss=0.263]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([8, 512])\n",
            "Text features: torch.Size([8, 512])\n",
            "Outputs shape: torch.Size([8, 2]), Labels shape: torch.Size([8])\n",
            "Loss: 0.2634\n",
            "Epoch 4 Complete - Avg Loss = 0.2278 - Accuracy = 90.98%\n",
            "\n",
            "=== Epoch 5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 5:   0%|          | 0/40 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 1\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:   2%|▎         | 1/40 [00:34<22:11, 34.14s/it, loss=0.215]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2147\n",
            "Epoch 5 Complete - Avg Loss = 0.0054 - Accuracy = 91.41%\n",
            "\n",
            "Batch 2\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:   5%|▌         | 2/40 [01:07<21:26, 33.86s/it, loss=0.177]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1775\n",
            "Epoch 5 Complete - Avg Loss = 0.0098 - Accuracy = 91.41%\n",
            "\n",
            "Batch 3\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:   8%|▊         | 3/40 [01:42<21:10, 34.34s/it, loss=0.311]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.3107\n",
            "Epoch 5 Complete - Avg Loss = 0.0176 - Accuracy = 89.58%\n",
            "\n",
            "Batch 4\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  10%|█         | 4/40 [02:18<20:56, 34.90s/it, loss=0.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2702\n",
            "Epoch 5 Complete - Avg Loss = 0.0243 - Accuracy = 89.84%\n",
            "\n",
            "Batch 5\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  12%|█▎        | 5/40 [02:52<20:06, 34.48s/it, loss=0.16]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1595\n",
            "Epoch 5 Complete - Avg Loss = 0.0283 - Accuracy = 90.62%\n",
            "\n",
            "Batch 6\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  15%|█▌        | 6/40 [03:25<19:16, 34.02s/it, loss=0.219]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2189\n",
            "Epoch 5 Complete - Avg Loss = 0.0338 - Accuracy = 90.89%\n",
            "\n",
            "Batch 7\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  18%|█▊        | 7/40 [03:59<18:41, 33.97s/it, loss=0.228]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2278\n",
            "Epoch 5 Complete - Avg Loss = 0.0395 - Accuracy = 90.85%\n",
            "\n",
            "Batch 8\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  20%|██        | 8/40 [04:33<18:08, 34.02s/it, loss=0.255]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2545\n",
            "Epoch 5 Complete - Avg Loss = 0.0458 - Accuracy = 91.02%\n",
            "\n",
            "Batch 9\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  22%|██▎       | 9/40 [05:07<17:31, 33.91s/it, loss=0.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2002\n",
            "Epoch 5 Complete - Avg Loss = 0.0509 - Accuracy = 91.32%\n",
            "\n",
            "Batch 10\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  25%|██▌       | 10/40 [05:41<17:05, 34.19s/it, loss=0.193]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1928\n",
            "Epoch 5 Complete - Avg Loss = 0.0557 - Accuracy = 91.33%\n",
            "\n",
            "Batch 11\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  28%|██▊       | 11/40 [06:15<16:29, 34.14s/it, loss=0.253]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2527\n",
            "Epoch 5 Complete - Avg Loss = 0.0620 - Accuracy = 91.34%\n",
            "\n",
            "Batch 12\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  30%|███       | 12/40 [06:49<15:53, 34.06s/it, loss=0.26]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2601\n",
            "Epoch 5 Complete - Avg Loss = 0.0685 - Accuracy = 91.15%\n",
            "\n",
            "Batch 13\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  32%|███▎      | 13/40 [07:23<15:13, 33.85s/it, loss=0.228]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2279\n",
            "Epoch 5 Complete - Avg Loss = 0.0742 - Accuracy = 91.11%\n",
            "\n",
            "Batch 14\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  35%|███▌      | 14/40 [07:57<14:46, 34.10s/it, loss=0.185]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1849\n",
            "Epoch 5 Complete - Avg Loss = 0.0788 - Accuracy = 91.35%\n",
            "\n",
            "Batch 15\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  38%|███▊      | 15/40 [08:31<14:08, 33.93s/it, loss=0.154]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1542\n",
            "Epoch 5 Complete - Avg Loss = 0.0827 - Accuracy = 91.51%\n",
            "\n",
            "Batch 16\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  40%|████      | 16/40 [09:05<13:33, 33.88s/it, loss=0.168]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1679\n",
            "Epoch 5 Complete - Avg Loss = 0.0869 - Accuracy = 91.85%\n",
            "\n",
            "Batch 17\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  42%|████▎     | 17/40 [09:38<12:58, 33.84s/it, loss=0.153]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1533\n",
            "Epoch 5 Complete - Avg Loss = 0.0907 - Accuracy = 92.05%\n",
            "\n",
            "Batch 18\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  45%|████▌     | 18/40 [10:12<12:22, 33.74s/it, loss=0.165]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1648\n",
            "Epoch 5 Complete - Avg Loss = 0.0948 - Accuracy = 92.10%\n",
            "\n",
            "Batch 19\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  48%|████▊     | 19/40 [10:46<11:50, 33.84s/it, loss=0.243]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2430\n",
            "Epoch 5 Complete - Avg Loss = 0.1009 - Accuracy = 91.86%\n",
            "\n",
            "Batch 20\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  50%|█████     | 20/40 [11:20<11:17, 33.88s/it, loss=0.174]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1739\n",
            "Epoch 5 Complete - Avg Loss = 0.1052 - Accuracy = 91.91%\n",
            "\n",
            "Batch 21\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  52%|█████▎    | 21/40 [11:53<10:40, 33.70s/it, loss=0.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2002\n",
            "Epoch 5 Complete - Avg Loss = 0.1102 - Accuracy = 92.11%\n",
            "\n",
            "Batch 22\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  55%|█████▌    | 22/40 [12:29<10:16, 34.25s/it, loss=0.147]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1474\n",
            "Epoch 5 Complete - Avg Loss = 0.1139 - Accuracy = 92.22%\n",
            "\n",
            "Batch 23\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  57%|█████▊    | 23/40 [13:02<09:38, 34.01s/it, loss=0.146]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1456\n",
            "Epoch 5 Complete - Avg Loss = 0.1176 - Accuracy = 92.29%\n",
            "\n",
            "Batch 24\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  60%|██████    | 24/40 [13:36<09:05, 34.12s/it, loss=0.172]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1723\n",
            "Epoch 5 Complete - Avg Loss = 0.1219 - Accuracy = 92.35%\n",
            "\n",
            "Batch 25\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  62%|██████▎   | 25/40 [14:11<08:33, 34.25s/it, loss=0.208]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2079\n",
            "Epoch 5 Complete - Avg Loss = 0.1271 - Accuracy = 92.34%\n",
            "\n",
            "Batch 26\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  65%|██████▌   | 26/40 [14:45<08:00, 34.31s/it, loss=0.209]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2088\n",
            "Epoch 5 Complete - Avg Loss = 0.1323 - Accuracy = 92.28%\n",
            "\n",
            "Batch 27\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  68%|██████▊   | 27/40 [15:19<07:22, 34.03s/it, loss=0.17]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1698\n",
            "Epoch 5 Complete - Avg Loss = 0.1365 - Accuracy = 92.33%\n",
            "\n",
            "Batch 28\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  70%|███████   | 28/40 [15:53<06:46, 33.91s/it, loss=0.16]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1604\n",
            "Epoch 5 Complete - Avg Loss = 0.1406 - Accuracy = 92.30%\n",
            "\n",
            "Batch 29\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  72%|███████▎  | 29/40 [16:27<06:14, 34.08s/it, loss=0.206]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2065\n",
            "Epoch 5 Complete - Avg Loss = 0.1457 - Accuracy = 92.27%\n",
            "\n",
            "Batch 30\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  75%|███████▌  | 30/40 [17:02<05:42, 34.25s/it, loss=0.184]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1843\n",
            "Epoch 5 Complete - Avg Loss = 0.1503 - Accuracy = 92.27%\n",
            "\n",
            "Batch 31\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  78%|███████▊  | 31/40 [17:38<05:12, 34.78s/it, loss=0.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2001\n",
            "Epoch 5 Complete - Avg Loss = 0.1553 - Accuracy = 92.29%\n",
            "\n",
            "Batch 32\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  80%|████████  | 32/40 [18:12<04:37, 34.74s/it, loss=0.211]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2110\n",
            "Epoch 5 Complete - Avg Loss = 0.1606 - Accuracy = 92.24%\n",
            "\n",
            "Batch 33\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  82%|████████▎ | 33/40 [18:47<04:02, 34.69s/it, loss=0.176]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1764\n",
            "Epoch 5 Complete - Avg Loss = 0.1650 - Accuracy = 92.23%\n",
            "\n",
            "Batch 34\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  85%|████████▌ | 34/40 [19:22<03:28, 34.68s/it, loss=0.133]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1331\n",
            "Epoch 5 Complete - Avg Loss = 0.1683 - Accuracy = 92.30%\n",
            "\n",
            "Batch 35\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  88%|████████▊ | 35/40 [19:55<02:50, 34.19s/it, loss=0.184]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1843\n",
            "Epoch 5 Complete - Avg Loss = 0.1729 - Accuracy = 92.30%\n",
            "\n",
            "Batch 36\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  90%|█████████ | 36/40 [20:29<02:16, 34.15s/it, loss=0.142]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1418\n",
            "Epoch 5 Complete - Avg Loss = 0.1765 - Accuracy = 92.38%\n",
            "\n",
            "Batch 37\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  92%|█████████▎| 37/40 [21:01<01:41, 33.72s/it, loss=0.273]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.2727\n",
            "Epoch 5 Complete - Avg Loss = 0.1833 - Accuracy = 92.31%\n",
            "\n",
            "Batch 38\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  95%|█████████▌| 38/40 [21:34<01:06, 33.38s/it, loss=0.147]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1468\n",
            "Epoch 5 Complete - Avg Loss = 0.1870 - Accuracy = 92.37%\n",
            "\n",
            "Batch 39\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([128, 3, 224, 224])\n",
            "Texts: torch.Size([128, 77])\n",
            "Labels: torch.Size([128])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5:  98%|█████████▊| 39/40 [22:07<00:33, 33.29s/it, loss=0.172]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([128, 512])\n",
            "Text features: torch.Size([128, 512])\n",
            "Outputs shape: torch.Size([128, 2]), Labels shape: torch.Size([128])\n",
            "Loss: 0.1716\n",
            "Epoch 5 Complete - Avg Loss = 0.1913 - Accuracy = 92.39%\n",
            "\n",
            "Batch 40\n",
            "Raw batch shapes:\n",
            "Images: torch.Size([8, 3, 224, 224])\n",
            "Texts: torch.Size([8, 77])\n",
            "Labels: torch.Size([8])\n",
            "Moved batch to device\n",
            "Encoding image features...\n",
            "Encoding text features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 40/40 [22:09<00:00, 33.23s/it, loss=0.368]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image features: torch.Size([8, 512])\n",
            "Text features: torch.Size([8, 512])\n",
            "Outputs shape: torch.Size([8, 2]), Labels shape: torch.Size([8])\n",
            "Loss: 0.3682\n",
            "Epoch 5 Complete - Avg Loss = 0.2005 - Accuracy = 92.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "def evaluate_model(model, data_loader, clip_model, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    total_loss = 0\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, texts, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
        "            images = images.to(device)\n",
        "            texts = texts.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Extract CLIP features\n",
        "            image_features = clip_model.encode_image(images).float()\n",
        "            text_features = clip_model.encode_text(texts).float()\n",
        "\n",
        "            # Forward pass through classifier\n",
        "            outputs = model(image_features, text_features)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"\\n✅ Evaluation Complete — Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"📉 Average Loss: {total_loss / len(data_loader):.4f}\")\n",
        "    print(\"\\n📊 Classification Report:\\n\", classification_report(all_labels, all_preds, target_names=[\"Real\", \"Fake\"]))\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "nLqlkV3mX0pl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Evaluating on Validation Set ===\")\n",
        "evaluate_model(model, val_loader, clip_model, device)\n",
        "\n",
        "print(\"\\n=== Evaluating on Test Set ===\")\n",
        "evaluate_model(model, test_loader, clip_model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw17puafXSYn",
        "outputId": "06da019d-7680-4194-8cf1-a9afcbf3a19a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluating on Validation Set ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 8/8 [04:21<00:00, 32.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Evaluation Complete — Accuracy: 88.60%\n",
            "📉 Average Loss: 0.2715\n",
            "\n",
            "📊 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.92      0.88      0.90       579\n",
            "        Fake       0.84      0.90      0.87       421\n",
            "\n",
            "    accuracy                           0.89      1000\n",
            "   macro avg       0.88      0.89      0.88      1000\n",
            "weighted avg       0.89      0.89      0.89      1000\n",
            "\n",
            "\n",
            "=== Evaluating on Test Set ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 8/8 [04:32<00:00, 34.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Evaluation Complete — Accuracy: 88.60%\n",
            "📉 Average Loss: 0.2801\n",
            "\n",
            "📊 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.95      0.86      0.90       608\n",
            "        Fake       0.81      0.93      0.86       392\n",
            "\n",
            "    accuracy                           0.89      1000\n",
            "   macro avg       0.88      0.89      0.88      1000\n",
            "weighted avg       0.89      0.89      0.89      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.886"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"clip_fakenews_classifier.pth\")\n",
        "print(\" Model saved.\")"
      ],
      "metadata": {
        "id": "NKhNVaGROTwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb49f111-9860-4179-a8df-efcbe38a8d3e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"clip_fakenews_classifier.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6me6tHv9Yj-M",
        "outputId": "f1d3de2f-ce8c-4dce-b21b-bd3bdd1e817c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_63955f3f-c29a-4e33-b10d-1f57403e4b7a\", \"clip_fakenews_classifier.pth\", 2365810)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FakeNewsClassifier().to(device)\n",
        "model.load_state_dict(torch.load(\"clip_fakenews_classifier.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAp9EbzbYpL_",
        "outputId": "7fa7ecc0-7e34-4882-bbd9-f6212fe787bb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FakeNewsClassifier(\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.3, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.3, inplace=False)\n",
              "    (6): Linear(in_features=128, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBGRDuBA1_oX",
        "outputId": "32008be7-b9ea-4591-b3c3-f4b97994e79b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.5 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def predict_from_gradio(text, image):\n",
        "    model.eval()\n",
        "\n",
        "    try:\n",
        "        image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "    except:\n",
        "        image_input = preprocess(Image.new(\"RGB\", (224, 224), (255, 255, 255))).unsqueeze(0).to(device)\n",
        "\n",
        "    text_input = clip.tokenize([text]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        image_features = clip_model.encode_image(image_input).float()\n",
        "        text_features = clip_model.encode_text(text_input).float()\n",
        "        outputs = model(image_features, text_features)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    label = predicted.item()\n",
        "    return \"Real News\" if label == 0 else \"Fake News\""
      ],
      "metadata": {
        "id": "yZGzBJFb2MPU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(\n",
        "    fn=predict_from_gradio,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"News Headline / Description\", placeholder=\"Enter the news content here...\"),\n",
        "        gr.Image(type=\"pil\", label=\"Associated Image\", sources=[\"upload\", \"clipboard\"])\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Result\"),\n",
        "    title=\"📰 Fake News Detection\",\n",
        "    description=\"This app uses OpenAI's CLIP model to detect fake news based on text + image.\"\n",
        ")\n",
        "\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "P2Pzo-gD2fDR",
        "outputId": "7f7512c2-9fe6-409e-a554-3d04fef4ef6b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2e816617e35b9c9ccb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2e816617e35b9c9ccb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}